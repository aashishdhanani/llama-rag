{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLAUDE_KEY = os.getenv(\"CLAUDE_KEY\")\n",
    "#MODEL = \"claude-3-7-sonnet-20250219\"\n",
    "MODEL = \"llama3.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\\n\\nHope that made you laugh! Do you want to hear another?\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "\n",
    "if MODEL.startswith(\"claude\"):\n",
    "    llm = ChatAnthropic(model=MODEL, api_key=CLAUDE_KEY)\n",
    "else:\n",
    "    llm = OllamaLLM(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL)\n",
    "    \n",
    "\n",
    "    \n",
    "llm.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta!\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = llm | parser\n",
    "chain.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "def load_pdfs(path):\n",
    "    documents = []\n",
    "    ctr = 1\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "\n",
    "            result = converter.convert(file_path)\n",
    "            content = result.document.export_to_markdown()\n",
    "\n",
    "            doc = Document(\n",
    "                page_content = content,\n",
    "                metadata = {\"source\": file_path}\n",
    "            )\n",
    "\n",
    "            print(f\"File {ctr}: {filename} loaded.\")\n",
    "            ctr += 1\n",
    "            documents.append(doc)\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: localsearch.pdf loaded.\n",
      "File 2: informed_search.pdf loaded.\n",
      "File 3: naivebayes.pdf loaded.\n",
      "File 4: adversarialsearch.pdf loaded.\n",
      "File 5: Search.pdf loaded.\n",
      "File 6: intelligentagents.pdf loaded.\n",
      "File 7: markov.pdf loaded.\n",
      "File 8: rl.pdf loaded.\n",
      "File 9: ml.pdf loaded.\n",
      "File 10: AI_Intro.pdf loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = load_pdfs(\"data/preprocessed\")\n",
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_markdown_files(documents, output_dir=\"data/processed_markdown\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Get the original filename from the source path\n",
    "        file_path = doc.metadata[\"source\"]\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        \n",
    "        # Create markdown file path\n",
    "        markdown_path = os.path.join(output_dir, f\"{base_name}.md\")\n",
    "        \n",
    "        # Write content to markdown file\n",
    "        with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(doc.page_content)\n",
    "        \n",
    "        # Update metadata to include markdown path\n",
    "        doc.metadata[\"markdown_path\"] = markdown_path\n",
    "        \n",
    "        print(f\"Exported: {markdown_path}\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: data/processed_markdown/localsearch.md\n",
      "Exported: data/processed_markdown/informed_search.md\n",
      "Exported: data/processed_markdown/naivebayes.md\n",
      "Exported: data/processed_markdown/adversarialsearch.md\n",
      "Exported: data/processed_markdown/Search.md\n",
      "Exported: data/processed_markdown/intelligentagents.md\n",
      "Exported: data/processed_markdown/markov.md\n",
      "Exported: data/processed_markdown/rl.md\n",
      "Exported: data/processed_markdown/ml.md\n",
      "Exported: data/processed_markdown/AI_Intro.md\n"
     ]
    }
   ],
   "source": [
    "all_documents = export_markdown_files(all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below. If you can't answer the question, reply \"I do not know\"\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If you can't answer the question, reply \"I do not know\"\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"here is a question\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Ant-Man.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": \"The name I was given was Ant Man\",\n",
    "        \"question\": \"What is my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aashishd/Desktop/llama-rag/.venv/lib/python3.9/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages, \n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Acrobat Distiller 11.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2022-01-31T17:50:48-06:00', 'author': 'Weihua', 'moddate': '2022-01-31T17:50:48-06:00', 'title': 'Microsoft PowerPoint - m2-agents.ppt [Compatibility Mode]', 'source': 'data/preprocessed/intelligentagents.pdf', 'total_pages': 27, 'page': 0, 'page_label': '1'}, page_content='Intelligent Agents\\nChapter 2'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 11.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2022-01-31T17:50:48-06:00', 'author': 'Weihua', 'moddate': '2022-01-31T17:50:48-06:00', 'title': 'Microsoft PowerPoint - m2-agents.ppt [Compatibility Mode]', 'source': 'data/preprocessed/intelligentagents.pdf', 'total_pages': 27, 'page': 25, 'page_label': '26'}, page_content='Utility-based agents\\nENVTrigger/Prioritize\\nGoals/Tasks\\nGoals Tasks\\nPercepts\\nActions\\nUpdate \\nWorld \\nModel\\nWorld Model\\nProblem Solving Methods\\nSelect \\ngoals/tasks\\nSelect Methods/\\nActions\\nUtility'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 11.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2022-01-31T17:50:48-06:00', 'author': 'Weihua', 'moddate': '2022-01-31T17:50:48-06:00', 'title': 'Microsoft PowerPoint - m2-agents.ppt [Compatibility Mode]', 'source': 'data/preprocessed/intelligentagents.pdf', 'total_pages': 27, 'page': 21, 'page_label': '22'}, page_content='Agent Types\\n• Simple reflex agents\\n• Model-based reflex agents• Goal-based agents• Utility-based agentsGenerality'),\n",
       " Document(metadata={'producer': 'Acrobat Distiller 11.0 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2022-01-31T17:50:48-06:00', 'author': 'Weihua', 'moddate': '2022-01-31T17:50:48-06:00', 'title': 'Microsoft PowerPoint - m2-agents.ppt [Compatibility Mode]', 'source': 'data/preprocessed/intelligentagents.pdf', 'total_pages': 27, 'page': 8, 'page_label': '9'}, page_content='Is a Vacuum-Cleaner Agent \\nRational?')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retriever.invoke(\"Rational Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PEAS stands for Performance measure, Environment, Actuators, Sensors. It's mentioned in the third document as one of the components of an intelligent agent, described in the outline on page 2.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter \n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"what is PEAS\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEAS stands for:\n",
      "\n",
      "• E (Environment): A description of the external world that the agent interacts with.\n",
      "• A (Actuators): The agents capabilities to interact with its environment by performing actions. \n",
      "• S (Sensors): The information the agent receives from its sensors about its environment and itself.\n",
      "• P (Performance Measure): The criteria for measuring how well or poorly an intelligent agent is doing.\n",
      "\n",
      "This is explained in more detail on page 14 of the document, as mentioned in the context provided."
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"What is PEAS?\"}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps:\n",
    "\n",
    "'''\n",
    "all the ai pdfs\n",
    "using docling for pdf handling \n",
    "scale it up\n",
    "make the overview pdf \n",
    "start the second project\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
