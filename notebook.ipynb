{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLAUDE_KEY = os.getenv(\"CLAUDE_KEY\")\n",
    "#MODEL = \"claude-3-7-sonnet-20250219\"\n",
    "MODEL = \"llama3.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta.\""
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "\n",
    "if MODEL.startswith(\"claude\"):\n",
    "    llm = ChatAnthropic(model=MODEL, api_key=CLAUDE_KEY)\n",
    "else:\n",
    "    llm = OllamaLLM(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL)\n",
    "    \n",
    "\n",
    "    \n",
    "llm.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A man walked into a library and asked the librarian, \"Do you have any books on Pavlov\\'s dogs and Schrödinger\\'s cat?\" The librarian replied, \"It rings a bell, but I\\'m not sure if it\\'s here or not.\"'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = llm | parser\n",
    "chain.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "def load_pdfs(path):\n",
    "    documents = []\n",
    "    ctr = 1\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "\n",
    "            result = converter.convert(file_path)\n",
    "            content = result.document.export_to_markdown()\n",
    "\n",
    "            doc = Document(\n",
    "                page_content = content,\n",
    "                metadata = {\"source\": file_path}\n",
    "            )\n",
    "\n",
    "            print(f\"File {ctr}: {filename} loaded.\")\n",
    "            ctr += 1\n",
    "            documents.append(doc)\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: localsearch.pdf loaded.\n",
      "File 2: informed_search.pdf loaded.\n",
      "File 3: naivebayes.pdf loaded.\n",
      "File 4: adversarialsearch.pdf loaded.\n",
      "File 5: Search.pdf loaded.\n",
      "File 6: intelligentagents.pdf loaded.\n",
      "File 7: markov.pdf loaded.\n",
      "File 8: rl.pdf loaded.\n",
      "File 9: ml.pdf loaded.\n",
      "File 10: AI_Intro.pdf loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = load_pdfs(\"data/preprocessed\")\n",
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_markdown_files(documents, output_dir=\"data/processed_markdown\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Get the original filename from the source path\n",
    "        file_path = doc.metadata[\"source\"]\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        \n",
    "        # Create markdown file path\n",
    "        markdown_path = os.path.join(output_dir, f\"{base_name}.md\")\n",
    "        \n",
    "        # Write content to markdown file\n",
    "        with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(doc.page_content)\n",
    "        \n",
    "        # Update metadata to include markdown path\n",
    "        doc.metadata[\"markdown_path\"] = markdown_path\n",
    "        \n",
    "        print(f\"Exported: {markdown_path}\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: data/processed_markdown/localsearch.md\n",
      "Exported: data/processed_markdown/informed_search.md\n",
      "Exported: data/processed_markdown/naivebayes.md\n",
      "Exported: data/processed_markdown/adversarialsearch.md\n",
      "Exported: data/processed_markdown/Search.md\n",
      "Exported: data/processed_markdown/intelligentagents.md\n",
      "Exported: data/processed_markdown/markov.md\n",
      "Exported: data/processed_markdown/rl.md\n",
      "Exported: data/processed_markdown/ml.md\n",
      "Exported: data/processed_markdown/AI_Intro.md\n"
     ]
    }
   ],
   "source": [
    "all_documents = export_markdown_files(all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localsearch.pdf: 10306 characters\n",
      "informed_search.pdf: 5997 characters\n",
      "naivebayes.pdf: 29500 characters\n",
      "adversarialsearch.pdf: 4210 characters\n",
      "Search.pdf: 12642 characters\n",
      "intelligentagents.pdf: 8101 characters\n",
      "markov.pdf: 15733 characters\n",
      "rl.pdf: 11718 characters\n",
      "ml.pdf: 10704 characters\n",
      "AI_Intro.pdf: 6980 characters\n"
     ]
    }
   ],
   "source": [
    "def count_characters(documents):\n",
    "    char_counts = {}\n",
    "    \n",
    "    for doc in documents:\n",
    "        source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "        char_count = len(doc.page_content)\n",
    "        char_counts[source] = char_count\n",
    "        \n",
    "        # Print as we go\n",
    "        print(f\"{os.path.basename(source)}: {char_count} characters\")\n",
    "    \n",
    "    return char_counts\n",
    "\n",
    "# Usage\n",
    "char_counts = count_characters(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents_by_structure(documents):\n",
    "    # First try to split by markdown headers\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"section\"),\n",
    "        (\"##\", \"subsection\"),\n",
    "        (\"###\", \"subsubsection\"),\n",
    "    ]\n",
    "    header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    \n",
    "    # For additional splitting of large sections\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,  # Larger than default since these are educational materials\n",
    "        chunk_overlap=150,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_splits = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Try header splitting first\n",
    "        try:\n",
    "            header_splits = header_splitter.split_text(doc.page_content)\n",
    "            \n",
    "            # Check if any splits are still too large\n",
    "            final_splits = []\n",
    "            for split in header_splits:\n",
    "                if len(split.page_content) > 2000:  # If section is still large\n",
    "                    smaller_splits = text_splitter.split_documents([Document(\n",
    "                        page_content=split.page_content,\n",
    "                        metadata={**doc.metadata, **split.metadata}\n",
    "                    )])\n",
    "                    final_splits.extend(smaller_splits)\n",
    "                else:\n",
    "                    final_splits.append(Document(\n",
    "                        page_content=split.page_content,\n",
    "                        metadata={**doc.metadata, **split.metadata}\n",
    "                    ))\n",
    "                    \n",
    "            all_splits.extend(final_splits)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback to regular splitting if header splitting fails\n",
    "            print(f\"Header splitting failed for {doc.metadata.get('source')}, using regular splitting\")\n",
    "            regular_splits = text_splitter.split_documents([doc])\n",
    "            all_splits.extend(regular_splits)\n",
    "    \n",
    "    return all_splits\n",
    "\n",
    "all_splits = split_documents_by_structure(all_documents)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI study assistant designed to help students with questions about their course materials. Your primary function is to provide accurate answers based solely on the information contained in the retrieved chunks of course documents. It is crucial that you do not add any information from your own knowledge or make up any details that are not explicitly stated in the provided text.\n",
      "\n",
      "Here are the retrieved chunks of course material:\n",
      "<context>\n",
      "Here is some context\n",
      "</context>\n",
      "\n",
      "The student has asked the following question:\n",
      "<student_question>\n",
      "here is a question\n",
      "</student_question>\n",
      "\n",
      "To answer the student's question, follow these steps:\n",
      "1. Carefully read and analyze the retrieved chunks of text.\n",
      "2. Identify any information directly relevant to the student's question.\n",
      "3. Formulate an answer using only the information found in the retrieved chunks.\n",
      "4. If you find conflicting information in different chunks, state this clearly in your answer.\n",
      "\n",
      "Format your response as follows:\n",
      "1. Begin with a <relevant_info> tag, where you will list the specific pieces of information from the chunks that are relevant to answering the question. Include the chunk number or identifier for each piece of information.\n",
      "2. Follow this with your <answer> tag, where you will provide a clear and concise answer to the student's question based solely on the information you listed in the relevant_info section.\n",
      "\n",
      "It is imperative that you only use information explicitly stated in the retrieved chunks. Do not add any additional information, explanations, or examples that are not present in the provided text, even if you believe them to be true or helpful.\n",
      "\n",
      "If the question cannot be fully answered using only the information in the retrieved chunks, state this clearly in your answer. Provide whatever partial information you can from the chunks, and explain what specific information is missing to fully answer the question.\n",
      "\n",
      "If the retrieved chunks contain no information relevant to the student's question, respond with:\n",
      "<answer>I apologize, but I couldn't find any information in the provided course materials that answers your question about [brief restatement of the question]. If you believe this topic should be covered in your course, you may want to consult your instructor or additional course resources.</answer>\n",
      "\n",
      "Remember, your role is to assist based strictly on the course materials provided, not to be a general knowledge resource. Accuracy and adherence to the given information are your top priorities.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an AI study assistant designed to help students with questions about their course materials. Your primary function is to provide accurate answers based solely on the information contained in the retrieved chunks of course documents. It is crucial that you do not add any information from your own knowledge or make up any details that are not explicitly stated in the provided text.\n",
    "\n",
    "Here are the retrieved chunks of course material:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "The student has asked the following question:\n",
    "<student_question>\n",
    "{question}\n",
    "</student_question>\n",
    "\n",
    "To answer the student's question, follow these steps:\n",
    "1. Carefully read and analyze the retrieved chunks of text.\n",
    "2. Identify any information directly relevant to the student's question.\n",
    "3. Formulate an answer using only the information found in the retrieved chunks.\n",
    "4. If you find conflicting information in different chunks, state this clearly in your answer.\n",
    "\n",
    "Format your response as follows:\n",
    "1. Begin with a <relevant_info> tag, where you will list the specific pieces of information from the chunks that are relevant to answering the question. Include the chunk number or identifier for each piece of information.\n",
    "2. Follow this with your <answer> tag, where you will provide a clear and concise answer to the student's question based solely on the information you listed in the relevant_info section.\n",
    "\n",
    "It is imperative that you only use information explicitly stated in the retrieved chunks. Do not add any additional information, explanations, or examples that are not present in the provided text, even if you believe them to be true or helpful.\n",
    "\n",
    "If the question cannot be fully answered using only the information in the retrieved chunks, state this clearly in your answer. Provide whatever partial information you can from the chunks, and explain what specific information is missing to fully answer the question.\n",
    "\n",
    "If the retrieved chunks contain no information relevant to the student's question, respond with:\n",
    "<answer>I apologize, but I couldn't find any information in the provided course materials that answers your question about [brief restatement of the question]. If you believe this topic should be covered in your course, you may want to consult your instructor or additional course resources.</answer>\n",
    "\n",
    "Remember, your role is to assist based strictly on the course materials provided, not to be a general knowledge resource. Accuracy and adherence to the given information are your top priorities.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"here is a question\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To answer the student\\'s question, I will follow the steps outlined:\\n\\n1. Carefully read and analyze the retrieved chunks of text:\\nThe only chunk of text is: \\n<context>\\nThe name I was given was Ant Man\\n</context>\\n\\n2. Identify any information directly relevant to the student\\'s question:\\nThe relevant piece of information is: \\n* The name the student was given was \"Ant Man\" (chunk 1) \\n\\n3. Formulate an answer using only the information found in the retrieved chunks:\\n\\n<relevant_info>\\n<context>1: The name I was given was Ant Man</context>\\n</relevant_info>\\n\\n<answer>\\nYour name is Ant Man.\\n</answer>\\n\\nThis answer is based solely on the information provided in the single chunk of text, which directly answers the student\\'s question about their name.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": \"The name I was given was Ant Man\",\n",
    "        \"question\": \"What is my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    all_splits,\n",
    "    embeddings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/preprocessed/intelligentagents.pdf', 'markdown_path': 'data/processed_markdown/intelligentagents.md', 'subsection': 'Outline'}, page_content='- · Agents and environments\\n- · Rationality\\n- · PEAS (Performance measure, Environment, Actuators, Sensors)\\n- · Environment types\\n- · Agent types'),\n",
       " Document(id='6cc3f8aa-72ab-4eea-b453-44e05b6c3a5e', metadata={'source': 'data/preprocessed/intelligentagents.pdf', 'markdown_path': 'data/processed_markdown/intelligentagents.md', 'subsection': 'Intelligent Agents'}, page_content='Chapter 2'),\n",
       " Document(metadata={'source': 'data/preprocessed/AI_Intro.pdf', 'markdown_path': 'data/processed_markdown/AI_Intro.md', 'subsection': 'An unintentionally funny story'}, page_content=\"- · One day Joe Bear was hungry. He asked his friend Irving Bird where some honey was. Irving told him there was a beehive in the oak tree. Joe threatened to hit Irving if he didn't tell him where some honey was. (The end.)  \\n<!-- image -->\"),\n",
       " Document(id='73e97dc2-995b-40ed-b8f3-17a5b8408019', metadata={'source': 'data/preprocessed/rl.pdf', 'markdown_path': 'data/processed_markdown/rl.md', 'subsection': 'Example: Model-Based Learning'}, page_content='Input Policy π'),\n",
       " Document(metadata={'source': 'data/preprocessed/adversarialsearch.pdf', 'markdown_path': 'data/processed_markdown/adversarialsearch.md', 'subsection': 'Minimax'}, page_content='- · Perfect play for deterministic games.\\n- · Ideas\\n- - assume the opponent always chooses a move that minimizes the desirability of states (from my perspective).\\n- - The heuristic evaluation at level i depends on the move (by the other player) at level i+1.'),\n",
       " Document(id='3287fc56-8214-45b7-bcb5-9ea6da9b98aa', metadata={'source': 'data/preprocessed/markov.pdf', 'markdown_path': 'data/processed_markdown/markov.md', 'subsection': 'Example: Grid World'}, page_content='<!-- image -->  \\nExit'),\n",
       " Document(id='30f30bca-6436-477c-be34-ce6c73636c74', metadata={'source': 'data/preprocessed/AI_Intro.pdf', 'markdown_path': 'data/processed_markdown/AI_Intro.md', 'subsection': 'Artificial Intelligence'}, page_content='An Introduction  \\nRussell and Norvig')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "# Create keyword-based retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(all_splits)\n",
    "bm25_retriever.k = 3  # Return top 3 keyword matches\n",
    "\n",
    "# Create vector retriever from your FAISS index\n",
    "vector_retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Combine them into a hybrid retriever\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "hybrid_retriever.invoke(\"PEAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<relevant_info>\\n- · Agents and environments (1)\\n- · PEAS (Performance measure, Environment, Actuators, Sensors) (no specific chunk number mentioned in relation to this acronym)</relevant_info>\\n\\n<answer>\\nThe acronym PEAS is explicitly stated as standing for Performance measure, Environment, Actuators, and Sensors.'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter \n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | hybrid_retriever | format_docs,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"What does PEAS stand for?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<relevant_info>\n",
      "From the provided chunks, I can find this relevant information:\n",
      "- \"Uninformed search strategies use only the information available in the problem definition (also called blind search)\"\n",
      "- \"Breadth-first search\" is listed as one of the uninformed search strategies\n",
      "</relevant_info>\n",
      "\n",
      "<answer>\n",
      "Based on the provided course materials, BFS stands for Breadth-first search, which is categorized as an uninformed search strategy. Uninformed search strategies (also called blind search) use only the information available in the problem definition.\n",
      "\n",
      "However, the retrieved chunks don't provide specific details about how BFS works, its characteristics, implementation, or properties. To fully understand BFS, you would need additional information that isn't present in the current material provided.\n",
      "</answer>"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"What is the search method BFS?\"}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
