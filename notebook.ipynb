{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLAUDE_KEY = os.getenv(\"CLAUDE_KEY\")\n",
    "MODEL = \"claude-3-7-sonnet-20250219\"\n",
    "#MODEL = \"llama3.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", additional_kwargs={}, response_metadata={'id': 'msg_015dpc5KNBaKV1cNB3wgsyzz', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 11, 'output_tokens': 17}, 'model_name': 'claude-3-7-sonnet-20250219'}, id='run-aa32c474-ac9c-4337-abc1-d060617210ca-0', usage_metadata={'input_tokens': 11, 'output_tokens': 17, 'total_tokens': 28, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "\n",
    "if MODEL.startswith(\"claude\"):\n",
    "    llm = ChatAnthropic(model=MODEL, api_key=CLAUDE_KEY)\n",
    "else:\n",
    "    llm = OllamaLLM(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL)\n",
    "    \n",
    "\n",
    "    \n",
    "llm.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = llm | parser\n",
    "chain.invoke(\"tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "def load_pdfs(path):\n",
    "    documents = []\n",
    "    ctr = 1\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(path, filename)\n",
    "\n",
    "            result = converter.convert(file_path)\n",
    "            content = result.document.export_to_markdown()\n",
    "\n",
    "            doc = Document(\n",
    "                page_content = content,\n",
    "                metadata = {\"source\": file_path}\n",
    "            )\n",
    "\n",
    "            print(f\"File {ctr}: {filename} loaded.\")\n",
    "            ctr += 1\n",
    "            documents.append(doc)\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: localsearch.pdf loaded.\n",
      "File 2: informed_search.pdf loaded.\n",
      "File 3: naivebayes.pdf loaded.\n",
      "File 4: adversarialsearch.pdf loaded.\n",
      "File 5: Search.pdf loaded.\n",
      "File 6: intelligentagents.pdf loaded.\n",
      "File 7: markov.pdf loaded.\n",
      "File 8: rl.pdf loaded.\n",
      "File 9: ml.pdf loaded.\n",
      "File 10: AI_Intro.pdf loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents = load_pdfs(\"data/preprocessed\")\n",
    "len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_markdown_files(documents, output_dir=\"data/processed_markdown\"):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Get the original filename from the source path\n",
    "        file_path = doc.metadata[\"source\"]\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        \n",
    "        # Create markdown file path\n",
    "        markdown_path = os.path.join(output_dir, f\"{base_name}.md\")\n",
    "        \n",
    "        # Write content to markdown file\n",
    "        with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(doc.page_content)\n",
    "        \n",
    "        # Update metadata to include markdown path\n",
    "        doc.metadata[\"markdown_path\"] = markdown_path\n",
    "        \n",
    "        print(f\"Exported: {markdown_path}\")\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported: data/processed_markdown/localsearch.md\n",
      "Exported: data/processed_markdown/informed_search.md\n",
      "Exported: data/processed_markdown/naivebayes.md\n",
      "Exported: data/processed_markdown/adversarialsearch.md\n",
      "Exported: data/processed_markdown/Search.md\n",
      "Exported: data/processed_markdown/intelligentagents.md\n",
      "Exported: data/processed_markdown/markov.md\n",
      "Exported: data/processed_markdown/rl.md\n",
      "Exported: data/processed_markdown/ml.md\n",
      "Exported: data/processed_markdown/AI_Intro.md\n"
     ]
    }
   ],
   "source": [
    "all_documents = export_markdown_files(all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localsearch.pdf: 10306 characters\n",
      "informed_search.pdf: 5997 characters\n",
      "naivebayes.pdf: 29500 characters\n",
      "adversarialsearch.pdf: 4210 characters\n",
      "Search.pdf: 12642 characters\n",
      "intelligentagents.pdf: 8101 characters\n",
      "markov.pdf: 15733 characters\n",
      "rl.pdf: 11718 characters\n",
      "ml.pdf: 10704 characters\n",
      "AI_Intro.pdf: 6980 characters\n"
     ]
    }
   ],
   "source": [
    "def count_characters(documents):\n",
    "    char_counts = {}\n",
    "    \n",
    "    for doc in documents:\n",
    "        source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "        char_count = len(doc.page_content)\n",
    "        char_counts[source] = char_count\n",
    "        \n",
    "        # Print as we go\n",
    "        print(f\"{os.path.basename(source)}: {char_count} characters\")\n",
    "    \n",
    "    return char_counts\n",
    "\n",
    "# Usage\n",
    "char_counts = count_characters(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents_by_structure(documents):\n",
    "    # First try to split by markdown headers\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"section\"),\n",
    "        (\"##\", \"subsection\"),\n",
    "        (\"###\", \"subsubsection\"),\n",
    "    ]\n",
    "    header_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    \n",
    "    # For additional splitting of large sections\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1500,  # Larger than default since these are educational materials\n",
    "        chunk_overlap=150,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_splits = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Try header splitting first\n",
    "        try:\n",
    "            header_splits = header_splitter.split_text(doc.page_content)\n",
    "            \n",
    "            # Check if any splits are still too large\n",
    "            final_splits = []\n",
    "            for split in header_splits:\n",
    "                if len(split.page_content) > 2000:  # If section is still large\n",
    "                    smaller_splits = text_splitter.split_documents([Document(\n",
    "                        page_content=split.page_content,\n",
    "                        metadata={**doc.metadata, **split.metadata}\n",
    "                    )])\n",
    "                    final_splits.extend(smaller_splits)\n",
    "                else:\n",
    "                    final_splits.append(Document(\n",
    "                        page_content=split.page_content,\n",
    "                        metadata={**doc.metadata, **split.metadata}\n",
    "                    ))\n",
    "                    \n",
    "            all_splits.extend(final_splits)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Fallback to regular splitting if header splitting fails\n",
    "            print(f\"Header splitting failed for {doc.metadata.get('source')}, using regular splitting\")\n",
    "            regular_splits = text_splitter.split_documents([doc])\n",
    "            all_splits.extend(regular_splits)\n",
    "    \n",
    "    return all_splits\n",
    "\n",
    "all_splits = split_documents_by_structure(all_documents)\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI study assistant designed to help students with questions about their course materials. Your primary function is to provide accurate answers based solely on the information contained in the retrieved chunks of course documents. It is crucial that you do not add any information from your own knowledge or make up any details that are not explicitly stated in the provided text.\n",
      "\n",
      "Here are the retrieved chunks of course material:\n",
      "<context>\n",
      "Here is some context\n",
      "</context>\n",
      "\n",
      "The student has asked the following question:\n",
      "<student_question>\n",
      "here is a question\n",
      "</student_question>\n",
      "\n",
      "To answer the student's question, follow these steps:\n",
      "1. Carefully read and analyze the retrieved chunks of text.\n",
      "2. Identify any information directly relevant to the student's question.\n",
      "3. Formulate an answer using only the information found in the retrieved chunks.\n",
      "4. If you find conflicting information in different chunks, state this clearly in your answer.\n",
      "\n",
      "Format your response as follows:\n",
      "1. Begin with a <relevant_info> tag, where you will list the specific pieces of information from the chunks that are relevant to answering the question. Include the chunk number or identifier for each piece of information.\n",
      "2. Follow this with your <answer> tag, where you will provide a clear and concise answer to the student's question based solely on the information you listed in the relevant_info section.\n",
      "\n",
      "It is imperative that you only use information explicitly stated in the retrieved chunks. Do not add any additional information, explanations, or examples that are not present in the provided text, even if you believe them to be true or helpful.\n",
      "\n",
      "If the question cannot be fully answered using only the information in the retrieved chunks, state this clearly in your answer. Provide whatever partial information you can from the chunks, and explain what specific information is missing to fully answer the question.\n",
      "\n",
      "If the retrieved chunks contain no information relevant to the student's question, respond with:\n",
      "<answer>I apologize, but I couldn't find any information in the provided course materials that answers your question about [brief restatement of the question]. If you believe this topic should be covered in your course, you may want to consult your instructor or additional course resources.</answer>\n",
      "\n",
      "Remember, your role is to assist based strictly on the course materials provided, not to be a general knowledge resource. Accuracy and adherence to the given information are your top priorities.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an AI study assistant designed to help students with questions about their course materials. Your primary function is to provide accurate answers based solely on the information contained in the retrieved chunks of course documents. It is crucial that you do not add any information from your own knowledge or make up any details that are not explicitly stated in the provided text.\n",
    "\n",
    "Here are the retrieved chunks of course material:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "The student has asked the following question:\n",
    "<student_question>\n",
    "{question}\n",
    "</student_question>\n",
    "\n",
    "To answer the student's question, follow these steps:\n",
    "1. Carefully read and analyze the retrieved chunks of text.\n",
    "2. Identify any information directly relevant to the student's question.\n",
    "3. Formulate an answer using only the information found in the retrieved chunks.\n",
    "4. If you find conflicting information in different chunks, state this clearly in your answer.\n",
    "\n",
    "Format your response as follows:\n",
    "1. Begin with a <relevant_info> tag, where you will list the specific pieces of information from the chunks that are relevant to answering the question. Include the chunk number or identifier for each piece of information.\n",
    "2. Follow this with your <answer> tag, where you will provide a clear and concise answer to the student's question based solely on the information you listed in the relevant_info section.\n",
    "\n",
    "It is imperative that you only use information explicitly stated in the retrieved chunks. Do not add any additional information, explanations, or examples that are not present in the provided text, even if you believe them to be true or helpful.\n",
    "\n",
    "If the question cannot be fully answered using only the information in the retrieved chunks, state this clearly in your answer. Provide whatever partial information you can from the chunks, and explain what specific information is missing to fully answer the question.\n",
    "\n",
    "If the retrieved chunks contain no information relevant to the student's question, respond with:\n",
    "<answer>I apologize, but I couldn't find any information in the provided course materials that answers your question about [brief restatement of the question]. If you believe this topic should be covered in your course, you may want to consult your instructor or additional course resources.</answer>\n",
    "\n",
    "Remember, your role is to assist based strictly on the course materials provided, not to be a general knowledge resource. Accuracy and adherence to the given information are your top priorities.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"here is a question\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<relevant_info>\\n1. The name I was given was Ant Man (Context 1)\\n</relevant_info>\\n\\n<answer>\\nMy name is Ant Man.\\n</answer>'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"context\": \"The name I was given was Ant Man\",\n",
    "        \"question\": \"What is my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    all_splits, \n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/preprocessed/intelligentagents.pdf', 'markdown_path': 'data/processed_markdown/intelligentagents.md', 'subsection': 'Intelligent Agents'}, page_content='Chapter 2'),\n",
       " Document(metadata={'source': 'data/preprocessed/rl.pdf', 'markdown_path': 'data/processed_markdown/rl.md', 'subsection': 'Example: Model-Based Learning'}, page_content='Input Policy π'),\n",
       " Document(metadata={'source': 'data/preprocessed/markov.pdf', 'markdown_path': 'data/processed_markdown/markov.md', 'subsection': 'Example: Grid World'}, page_content='<!-- image -->  \\nExit'),\n",
       " Document(metadata={'source': 'data/preprocessed/AI_Intro.pdf', 'markdown_path': 'data/processed_markdown/AI_Intro.md', 'subsection': 'Artificial Intelligence'}, page_content='An Introduction  \\nRussell and Norvig')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "retriever.invoke(\"PEAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<relevant_info>\\nI've carefully examined all the provided chunks of course material, but I don't see any information that defines or explains what the acronym PEAS stands for.\\n</relevant_info>\\n\\n<answer>I apologize, but I couldn't find any information in the provided course materials that answers your question about what PEAS stands for. If you believe this topic should be covered in your course, you may want to consult your instructor or additional course resources.</answer>\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter \n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever | format_docs,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"What does PEAS stand for?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<relevant_info>\n",
      "After reviewing all the provided chunks, I cannot find any information that defines or explains what PEAS stands for.\n",
      "</relevant_info>\n",
      "\n",
      "<answer>I apologize, but I couldn't find any information in the provided course materials that answers your question about what PEAS stands for. The retrieved chunks focus on genetic algorithms, 8-queens problem, value iteration, and brief mentions of state representation, but there is no mention of PEAS or its definition. If you believe this topic should be covered in your course, you may want to consult your instructor or additional course resources.</answer>"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"What does PEAS stand for?\"}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps:\n",
    "\n",
    "'''\n",
    "get rag to work\n",
    "make the overview pdf \n",
    "start the second project\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
