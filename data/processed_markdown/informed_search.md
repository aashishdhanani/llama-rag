## Informed search algorithms

## Outline

Informed Search: use domain-specific hints about the location of goals, beyond the definition of the problem itself.

- · Heuristic Search Methods
- · Best-first search algorithms
- - Greedy best-first search
- - A * search
- · Admissible Heuristic
- · Relaxed Problems

## Heuristic Search Methods

node to be expanded

- · Use an evaluation function f(n) for each node
- -Evaluation function f(n) = f(h(n)) (heuristic)
- h(n)= estimate of cost from n to goal
- h(n)=0 if n is a goal node
- -Order the nodes in fringe in decreasing order of desirability.
- -Expand most desirable unexpanded node. (lowest  distance)
- · Focus on states estimated to be most desirable (i.e. states with lowest or highest heuristic values).
- · The performance highly depends on how good is its h(n).
- · A good heuristic function can often find good (though possibly non-optimal) solutions in less than exponential time.

## Additional thoughts on H

- · People often are satisfied with a good, though not optimal, solutions. (could you think of a ex.?)
- · Although heuristic search may not be better than uninformed search in worst cases, worst cases rarely arise in the real world.
- · Trying to understand why a heuristic works, or why it does not work, often leads to a deeper understanding of the problem.
- · There is a trade-off between the time spent in computing heuristic values and the time spent in search.

## Greedy best-first search

- · Idea: expands the node that appears to be closest to goal.
- · Evaluation function f(n)= h(n)
- · e.g., h(n) =straight-line distance from n to

Bucharest

## Romania with step costs in km

<!-- image -->

## Greedy best-first search example

<!-- image -->

## Properties of greedy best-first search

- · Complete?
- · Time?
- · Space?
- · Optimal?

## Properties of greedy best-first search

- · Complete? Yes - in a finite tree. No - can get stuck in loops in infinite trees. e.g.,
- · Time? O(b m ) , (suffer the same defects as DFS) but a good heuristic can give dramatic improvement ( O(d) ) ……
- · Space? O(b m )
- · Optimal? No

<!-- image -->

## A * search

- · Ideas
- - Minimizing the total estimated solution cost.
- - Avoid expanding paths that are already expensive
- · Evaluation function f(n) = g(n) + h(n)
- -g(n) = cost to reach n from root
- -h(n) = cost from n to goal
- -f(n) = estimated total cost of path through n to goal

<!-- image -->

## A * search example

<!-- image -->

• BFS, DFS, Uniform-cost search are special cases of A*

- BFS: f(n)=depth(n)

- DFS: f(n)=-depth(n)

- UCS: f(n)=g(n).

## Properties of A*

- · Complete?
- · Time?
- · Space?
- · Optimal?

## Properties of A*

- · Complete? Yes (unless there are infinitely many nodes with f(n) ≤ f(G) ).
- · Time? Exponential. A* expands all nodes with f(n)&lt;C*.
- · Space? Keeps all nodes in memory.
- · Optimal? Depends on quality of h. Yes, if h is admissible ( TREE-SEARCH ) or consistent ( GRAPH-SEARCH ).

## Admissible heuristics

Theorem: If h(n) is admissible, A * using TREESEARCH is optimal.

- · A heuristic h(n) is admissible iff

 n h(n) ≤ h * (n), where h * (n) is the true cost to reach the goal state from n .

- · An admissible heuristic never overestimates the cost to reach the goal, i.e., it is optimistic.
- · Question: h SLD

(n) is admissible?

## Admissible heuristics

- · Question: h SLD (n) is admissible? Yes , because the straight-line distance never overestimates the actual road distance.

## Optimality of A * (proof)

- · Suppose some suboptimal goal G2 has been generated and is in the fringe. Let n be an unexpanded node in the fringe such that n is on a shortest path to an optimal goal G .

<!-- image -->

## Optimality of A * (proof)

- · Suppose some suboptimal goal G2 has been generated and is in the fringe. Let n be an unexpanded node in the fringe such that n is on a shortest path to an optimal goal G .
- · f(n) = g(n)+h(n)
- · h(n) ≤
- h*(n), h is admissible      g(n)+h(n) ≤ g(n)+ h*(n)      f(n) ≤ f(G)
- · f(G )  = g(G )  since 2 2 h (G 2 ) = 0
- · f(G)   = g(G) since h (G) = 0                     f(G) &lt; f(G

<!-- image -->

2

- · g(G) &lt; g(G )   since G 2 2 is suboptimal

So A * will never select G 2 for expansion. So A* is optimal.

)

f(n) &lt; f(G )

2

## Consistent heuristics

Theorem: If h(n) is consistent, A * using GRAPH-SEARCH is optimal.

- · A heuristic is consistent if for every node n , every successor n' of n generated by any action a ,

<!-- image -->

So the first goal node selected for expansion must be optimal, since all later nodes will be at least as expensive.

Every consistent heuristic is admissible. h SLD (n) is consistent.

## Example of Admissible heuristics

## The 8-puzzle problem

<!-- image -->

2

4

7

Goal State

5

6

## Example of Admissible Heuristics

## Complexity of the problem in general

E.g., for the 8-puzzle:

- · h 1 (n) = number of misplaced tiles
- · h 2 (n) = total Manhattan distance

Average b: 3

Average d (step): 22

State space: b d =3 22 =3

 10 10

including repeated states

State space: 170,000 without repeated

states

(i.e., # of squares from desired location of each tile)

<!-- image -->

## Relaxed problems

- · A problem with fewer restrictions on the actions is called a relaxed problem.
- · The cost of an optimal solution to a relaxed problem is an admissible heuristic for the original problem.

* Pr o C oblem Original * Pr Re r C oblem laxed ≥

## An 8-puzzle example

<!-- image -->

- · A tile can move A-&gt;B if
- -A is horizontally/vertically adjacent B, and
- -B is blank.
- · Relaxed problem:
- -(1) A tile can move A-&gt;B.
- -(2) A tile can move A-&gt;B, if A is adjacent B.
- -(3) A tile can move A-&gt;B, if B is blank.
- · If the rules of the 8-puzzle are relaxed so that a tile can move anywhere (1), then h 1 (n) gives the shortest solution.
- · If the rules are relaxed so that a tile can move to any adjacent square (2), then h 2 (n) gives the shortest solution.