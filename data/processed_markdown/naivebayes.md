## Machine Learning 1 Na√Øve Bayes

<!-- image -->

## Types of Learning Problems

- ‚ñ† Supervised learning: correct answers for each training example
- ‚ñ† Classification: learning predictor with discrete outputs
- ‚ñ† Regression: learning predictor with real-valued outputs

‚ñ† Unsupervised learning: no correct answers, just find good representations / features of the data

- ‚ñ†
- Reinforcement learning: reward function, no correct answers

## Machine Learning Roadmap

- ‚ñ† Define the problem
- ‚ñ† Type of problem, domain (i.e. spam filtering, digit recognition)
- ‚ñ† Look at several learning approaches / models
- ‚ñ† Na√Øve Bayes (today), Perceptrons , Logistic Regression (next week)
- ‚ñ† How to find model parameters:
- ‚ñ† Maximum Likelihood
- ‚ñ† Themes throughout
- ‚ñ† Working with data
- ‚ñ† Preventing overfitting
- ‚ñ† Evaluating performance

## Classification

<!-- image -->

## Classification and Machine Learning

- ‚ñ† Dataset: each data point, x, is associated with some label (aka class), y
- ‚ñ† Goal of classification: given inputs x, write an algorithm to predict labels y
- ‚ñ† Workflow of classification process:
- ‚ñ† Input is provided to you
- ‚ñ† Extract features from the input: attributes of the input that characterize each x and hopefully help with classification
- ‚ñ† Run some machine learning algorithm on the features: today, Na√Øve Bayes
- ‚ñ† Output a predicted label y

<!-- image -->

## Training

- ‚ñ† Big idea: ML algorithms learn patterns between features and labels from data
- ‚ñ† You don't have to reason about the data yourself
- ‚ñ† You're given training data : lots of example datapoints and their actual labels

<!-- image -->

Training: Learn patterns from labeled data, and periodically test how well you're doing

<!-- image -->

<!-- image -->

Eventually, use your algorithm to predict labels for unlabeled data

- ‚ñ† Input: an email
- ‚ñ† Output: spam/ham

## ‚ñ† Setup:

- ‚ñ† Get a large collection of example emails, each labeled 'spam' or 'ham'
- ‚ñ† Note: someone has to hand label all this data!
- ‚ñ† Want to learn to predict labels of new, future emails
- ‚ñ† Features: The attributes used to make the ham / spam decision
- ‚ñ† Words: FREE!
- ‚ñ† Text Patterns: $dd, CAPS
- ‚ñ† Non-text: SenderInContacts, WidelyBroadcast
- ‚ñ† ‚Ä¶

## Example: Spam Filter

Dear Sir.

<!-- image -->

<!-- image -->

<!-- image -->

First, I must solicit your confidence in this transaction, this is by virture of its nature as being utterly confidencial and top secret. ‚Ä¶

TO BE REMOVED FROM FUTURE MAILINGS, SIMPLY REPLY TO THIS MESSAGE AND PUT "REMOVE" IN THE SUBJECT.

- 99 MILLION EMAIL ADDRESSES FOR ONLY $99

Ok, Iknow this is blatantly OT but I'm beginning to go insane. Had an old Dell Dimension XPS sitting in the corner and decided to put it to use, I know it was working pre being stuck in the corner, but when I plugged it in, hit the power nothing happened.

## Example: Digit Recognition

- ‚ñ† Input: images / pixel grids
- ‚ñ† Output: a digit 0-9

## ‚ñ† Setup:

<!-- image -->

- ‚ñ† Get a large collection of example images, each labeled with a digit
- ‚ñ† Note: someone has to hand label all this data!
- ‚ñ† Want to learn to predict labels of new, future digit images
- ‚ñ† Features: The attributes used to make the digit decision
- ‚ñ† Pixels: (1,1)=ON
- ‚ñ† Shape Patterns: NumComponents (Number of connected regions), AspectRatio (Height-to-width ratio), NumLoops (Number of closed loops (e.g., '8' has two loops)).
- ‚ñ† These features help the model distinguish between similar-looking digits like '1' and '7' or '3' and '8'.

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

0

1

2

1

??

## Other Classification Tasks

- ‚ñ† Classification: given inputs x, predict labels (classes) y

## ‚ñ† Examples:

- ‚ñ† Object recognition input: images; classes: object type
- ‚ñ† Medical diagnosis input: symptoms; classes: diseases
- ‚ñ† Automatic essay grading input: document; classes: grades
- ‚ñ† Fraud detection input: account activity; classes: fraud / no fraud
- ‚ñ† Customer service email routing input: a customer service email; classes: billing, technical support, account management, sales, shipping, returns, product inquiry, etc.
- ‚ñ† ‚Ä¶many more
- ‚ñ† Classification is an important commercial technology!

<!-- image -->

## Model-Based Classification

<!-- image -->

## Model-Based Classification

## ‚ñ† Model-based approach

- ‚ñ† Build a model (e.g. Na√Øve Bayes) where both the label and features are random variables
- ‚ñ† Instantiate any observed features
- ‚ñ† Query for the distribution of the label conditioned on the features

## ‚ñ† Challenges

- ‚ñ† What structure should the model have?
- ‚ñ† How should we learn its parameters?

<!-- image -->

## Na√Øve Bayes Model

## ‚ñ† Na√Øve Bayes: Assume all features are independent effects of the label.

- ‚ñ† This simplification is the 'na√Øve' assumption : it ignores correlations between features, making computation easier
- ‚ñ† While this assumption is often not true in reality, it simplifies computations and still performs surprisingly well in practice.

## ‚ñ† Random variables:

- ‚ñ† Y = The label
- ‚ñ† F1, F , ‚Ä¶, F 2 n = The n features

<!-- image -->

## ‚ñ† Parameters: Probability tables:

- ‚ñ† ùëÉ·à∫ùëå·àª = Probability of each label, given no information about the features.

A Bayes Net. Each node represents a random variable. An arrow from A ‚Üí B means that A in fl uences B (i.e., B's probability depends on A).

- ‚ñ† Sometimes called the prior .
- ‚ñ† Example: What's the probability that any given email is spam before looking at its content?
- ‚ñ† ùëÉ·à∫ùêπùëñ | ùëå·àª = One table per feature. Probability of a feature, given the label.
- ‚ñ† Example: What's the chance the word 'FREE' appears given that the email is spam?

## Domain 1: Na√Øve Bayes for Digits

## ‚ñ† Simple digit recognition version:

- ‚ñ† One feature (variable) Fi,j for each grid position &lt;i,j&gt;
- ‚ñ† Feature values are on / off, based on whether intensity is more or less than 0.5 in underlying image
- ‚ñ† Each input maps to a feature vector, e.g. F 0,0 =0  F 0,1 =0  F 0,2 =1  F 0,3 =1  F 0,4 =1 ‚Ä¶ F 7,7 =0
- ‚ñ† Here: lots of features, each is binary valued
- ‚ñ† n : # of features. n = 8√ó8 = 64 pixels.
- ‚ñ† |F| : # of values a single feature can take. |F| = 2 (0 or 1).
- ‚ñ† |Y| : # of classes. |Y|=10.

<!-- image -->

## ‚ñ† What are the parameters to learn of this model?

- ‚ñ† P(Y = y) - the prior probability of each digit class (how often each digit appears). Total # of prior probabilities to learn =|Y|=10.
- ‚ñ† P(F , ·µ¢ ‚±º | Y = y) - the likelihood: for each class and each pixel, the probability that the pixel is on (1) or off (0). Total # of conditional probabilities to learn =|Y|√ó n √ó|F| = 10 √ó 64 √ó 2 = 1280.

## Domain 1: Na√Øve Bayes for Digits: Parameters

<!-- image -->

<!-- image -->

## Domain 2: Na√Øve Bayes for Text

## ‚ñ† Bag-of-words Na√Øve Bayes:

- ‚ñ† Features: Wi is the word at positon i
- ‚ñ† As before: predict label conditioned on feature variables (spam vs. ham)
- ‚ñ† As before: assume features are conditionally independent given label
- ‚ñ† New: each Wi is identically distributed, so P(W1|Y) = P(W2|Y) = ‚Ä¶
- ‚ñ† We don't care where a word appears, just whether it appears.

<!-- image -->

## ‚ñ† 'Tied' distributions and bag-of-words

- ‚ñ† Usually, each feature (word position) would get its own conditional probability distribution P(F|Y)
- ‚ñ† In a bag-of-words model
- ‚ñ† Each position is identically distributed.
- ‚ñ† All positions share the same (i.e. Tied) conditional probs P(W|Y).
- ‚ñ† Pro: simpler and more efficient. Con: the model ignores word order.
- ‚ñ† Called 'bag-of-words' because model is insensitive to word order or reordering

free our offer try please please try our free offer

## Domain 2: Na√Øve Bayes for Text: Parameters

## ‚ñ† What are the parameters?

- ‚ñ† n = # of words.
- ‚ñ† |F| = 2 (is this word in the email or not).
- ‚ñ† |Y| = 2 (ham or spam).

ùëÉ ùëä‡Øú ùë¶ = ‡Øñ‡Ø¢‡Ø®‡Ø°‡Øß ‡Ø¢‡Øô ‡Ø™‡Ø¢‡Ø•‡Øó ‡Øê ‡≥î ‡Øú‡Ø° ‡Øñ‡Øü‡Øî‡Ø¶‡Ø¶ ‡Ø¨ ‡¨æ ‡¨µ

‡Øß‡Ø¢‡Øß‡Øî‡Øü ‡Ø™‡Ø¢‡Ø•‡Øó‡Ø¶ ‡Øú‡Ø° ‡Øñ‡Øü‡Øî‡Ø¶‡Ø¶ ‡Ø¨ ‡¨æ ‡Øè

Wi   : a word in the vocabulary y: class label (spam or ham)

V: total number of unique words in the vocabulary (used for smoothing) The +1 and +V come from Laplace smoothing , which prevents zero probabilities for unseen words.

## Na√Øve Bayes Model

- ‚ñ† In general, the joint probability (posterior) of the label and all features in Na√Øve Bayes model is:

|Y| parameters n x |F| x |Y| parameters

- ‚ñ† Weonly have to specify how each feature depends on the class
- ‚ñ† Total number of parameters is linear in n
- ‚ñ† Without the Na√Øve assumption (then the features can be dependent on each other), we need  Y ‚à£ ‚à£ √ó ‚à£ F ‚à£ n values
- ‚ñ† Model is very simplistic, but often works anyway

<!-- image -->

## Inference for Na√Øve Bayes

- ‚ñ† Goal: compute posterior distribution over label variable Y
- ‚ñ† Step 1: get joint probability of label and evidence for each label

<!-- formula-not-decoded -->

- ‚ñ† Step 2: sum to get probability of evidence
- ‚ñ† Step 3: normalize by dividing Step 1 by Step 2

<!-- formula-not-decoded -->

## ‚ñ† Model:

- ‚ñ† Parameters:

## Example: Spam Filtering

P(Y)

P(Wlspam)

P(WIham)

ham : 0.66

spam: 0.33

to

:

0.0153

the :

0.0210

to : 0.0133

you :

0.0093

'you' is not listed: assume a small value (e.g., Laplace smoothing gives ~0.0001)

Suppose we have a short email with three words: "the", "to", "you"

Step 1 Compute the joint probabilities: P(spam,"the","to","you") = P(spam) √ó P('the' | spam) √ó P('to' | spam) √ó P('you' | spam) = 0.33 √ó 0.0156 √ó 0.0153 √ó 0.0093 ‚âà 7.34 √ó 10 -7 P(ham,"the","to","you") = P(ham) √ó P('the' | ham) √ó P('to' | ham) √ó P('you' | ham) = 0.66 √ó 0.0210 √ó 0.0133 √ó 0.0001 ‚âà 1.84 √ó 10 -7 Step 2 Compute total probability of evidence (denominator) P("the", "to", "you") = 7.34√ó10 -7 + 1.84√ó10 -7 = 9.18√ó10 -7 Step 3 Normalize to get posterior P(spam ‚à£ "the", "to", "you") = ‡¨ª ‡¨∑‡¨∏‡µà‡¨µ‡¨¥ ‡∞∑‡∞≥ . ‡¨Ω ‡¨µ‡¨º‡µà‡¨µ‡¨¥ ‡∞∑‡∞≥ . ‡µé 0.799 P(ham ‚à£ "the", "to", "you") = ‡¨µ ‡¨º‡¨∏‡µà‡¨µ‡¨¥ ‡∞∑‡∞≥ . ‡¨Ω ‡¨µ‡¨º‡µà‡¨µ‡¨¥ ‡∞∑‡∞≥ . ‡µé 0.201 Final Classification ÔÇÆ spam , since it has a higher posterior probability ( ‚âà 80%).

## General Na√Øve Bayes

## ‚ñ† What do we need in order to use Na√Øve Bayes?

- ‚ñ† Inference method (we just saw this part)
- ‚ñ† Start with a bunch of probabilities: P(Y) and the P(Fi|Y) tables
- ‚ñ† Use standard inference to compute P(Y|F1‚Ä¶Fn)
- ‚ñ† Nothing new here
- ‚ñ† Estimates of local conditional probability tables
- ‚ñ† P(Y), the prior over labels
- ‚ñ† P(Fi |Y) for each feature (evidence variable)
- ‚ñ† These probabilities are collectively called the parameters of the model and denoted by ÔÅ±
- ‚ñ† They typically come from training data counts

## Parameter Estimation

<!-- image -->

## Parameter Estimation

- ‚ñ† Estimating the distribution of a random variable
- ‚ñ† Elicitation: ask a human (why is this hard?)
- ‚ñ† Empirically: use training data (learning!)
- ‚ñ† Example: The parameter Œ∏ is the true fraction of red beans in the jar. You don't know Œ∏ but would like to estimate it.
- ‚ñ† Collecting training data: You randomly pull out 3 beans:
- ‚ñ† Estimating Œ∏ using counts, you guess 2/3 of beans in the jar are red.
- ‚ñ† Can we mathematically show that using counts is the 'right' way to estimate Œ∏ ?

<!-- image -->

<!-- image -->

<!-- image -->

<!-- image -->

## Parameter Estimation with Maximum Likelihood

- ‚ñ† Œ∏ is the true fraction of red beans in the jar (i.e. P(red | Œ∏ ) = Œ∏ )
- ‚ñ† Can we mathematically show that using counts is the 'right' way to estimate Œ∏ ?
- ‚ñ† Maximum likelihood estimation: Choose the Œ∏ value that maximizes the probability of the observation
- ‚ñ† In other words, choose the Œ∏ value that maximizes P(observation | Œ∏ )
- ‚ñ† For our problem:
- P(observation | Œ∏ )
- = P(randomly selected 2 red and 1 blue | Œ∏ of beans are red)
- = P(red | Œ∏ ) * P(red | Œ∏ ) * P(blue | Œ∏ )
- = Œ∏ 2 (1 Œ∏ )
- ‚ñ† Wewant to compute:
- argmax Œ∏ 2 (1 Œ∏ ) Œ∏

## Parameter Estimation with Maximum Likelihood

## ‚ñ† Wewant to compute:

<!-- image -->

## ‚ñ† Set derivative to 0, and solve!

- ‚ñ† Commonissue: The likelihood (expression we're maxing) is the product of a lot of probabilities. This can lead to complicated derivatives.
- ‚ñ† Solution: Maximize the log-likelihood instead (this will turn products to sums), which are easier to differentiate.
- ‚ñ† Useful fact:

argmax f( Œ∏ ) = argmax ln f( Œ∏ )

Œ∏

## Parameter Estimation with Maximum Likelihood

$$argmax argmax In (02(1 = 0)) d In (02(1 = 0)) = 0 d0 4 [In(02) + In(1 _ 0] = 0 d [2 In(0) + In(1 = 0)] = 0 d0 42ln(0) + d0 d0 2 1 = 0 1 = 0 2 = 3$$

$$02(1 = 0)$$

Find Œ∏ that maximizes likelihood

Find Œ∏ that maximizes log-likelihood (will be the same Œ∏ )

Set derivative to 0

Logarithm rule: products become sums

Logarithm rule: exponentiation becomes multiplication

Now we can derive each term of the original product separately

Reminder: Derivative of ln( Œ∏ ) is 1/ Œ∏

Use algebra to solve for Œ∏ . If we used arbitrary red and blue counts r and b instead of r=2 and b=1, we'd get Œ∏ = r / (r+b), the count estimate.

## Parameter Estimation with Maximum Likelihood (General Case)

- ‚ñ† Model :

blue red

ùëã

ùëÉ·à∫ùëã ùúÉ·àª

1

‡µÜùúÉ

ùúÉ

|

- ‚ñ† Data: draw ùëÅ balls, ùëÅ r come up red and ùëÅ b come up blue ‚ñ† Dataset ùê∑ ‡µå ùë• 1 , ‚Ä¶, ùë• N of N ball draws

<!-- formula-not-decoded -->

<!-- image -->

- ‚ñ† Maximum Likelihood Estimation : find ùúÉ that maximizes P D| ·à∫ ùúÉ·àª :

<!-- formula-not-decoded -->

Take derivative and set to 0:

<!-- formula-not-decoded -->

## Parameter Estimation with Maximum Likelihood

- ‚ñ† Collectively name all model parameters (i.e. probability tables) as ùúÉ
- ‚ñ† Maximum Likelihood Estimation : find ùúÉ that maximizes P Data| ·à∫ ùúÉ·àª
- ‚ñ† In practice, maximize log P instead because computation is easier
- ‚ñ† To solve, take derivative and set to 0
- ‚ñ† For Na√Øve Bayes maximum likelihood estimates of prob. tables are:

```
ùëÉ·à∫ùë¶·àª ‡µå # of occurences of class ùë¶ total # of observations
```

ùëÉ ùëì ùë¶·àª ‡µå # of occurences of feature ùëì and class ùë¶ total # of occurences of class ùë¶

- ‚ñ† Need to be careful though ‚Ä¶ let's see what can go wrong..

## What is the best way to fit this data?

<!-- image -->

x

## Empirical Risk (training error) Minimization

- ‚ñ† How should we evaluate the quality of our model?
- ‚ñ† Empirical risk minimization
- ‚ñ† Basic principle of machine learning
- ‚ñ† Wewant the model (classifier, etc) that does best on the true test distribution
- ‚ñ† Don't know the true distribution so pick the best model on our actual training set
- ‚ñ† Finding 'the best' model on the training set is phrased as an optimization problem
- ‚ñ† Main worry: overfitting to the training set
- ‚ñ† Better with more training data (less sampling variance)
- ‚ñ† Better if we limit the complexity of our hypotheses (regularization and/or small hypothesis spaces)
- ‚ñ† Another worry: our training distribution doesn't match true distribution

## Underfitting and Overfitting

<!-- image -->

<!-- image -->

<!-- image -->

## Example: Overfitting

2 wins!!

<!-- image -->

## Generalization and Overfitting

## ‚ñ† Relative frequency parameters will overfit the training data!

- ‚ñ† Just because we never saw a 3 with pixel (15,15) on during training doesn't mean we won't see it at test time
- ‚ñ† Unlikely that every occurrence of 'minute' is 100% spam
- ‚ñ† Unlikely that every occurrence of 'seriously' is 100% ham
- ‚ñ† What about all the words that don't occur in the training set at all?
- ‚ñ† In general, we can't go around giving unseen events zero probability
- ‚ñ† As an extreme case, imagine using the entire email as the only feature
- ‚ñ† Would get the training data perfect (if deterministic labeling)
- ‚ñ† Wouldn't generalize at all
- ‚ñ† Just making the bag-of-words assumption gives us some generalization, but isn't enough
- ‚ñ† To generalize better: we need to smooth/regularize the estimates

## Smoothing

<!-- image -->

## Laplace Smoothing

## ‚ñ† Laplace's estimate:

- ‚ñ† Pretend you saw every outcome once more than you actually did

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

- ¬∑ c(x): count of x
- ¬∑ N: total observations
- ¬∑ ‚à£ X : number of possible outcomes (e.g., red, blue ‚à£ ‚Üí |X| = 2)

Add 1 to each count as if we had seen each outcome once more than we did

<!-- image -->

<!-- image -->

<!-- image -->

P(red) = 2/3 ÔÇª

0.67 P(blue) = 1/3 ÔÇª 0.33 PLAP (red) = (2+1)/(3+2)=3/5=0.6

PLAP (blue) = (1+1)/(3+2)=2/5=0.4

## Generalized Laplace Smoothing

## ‚ñ† Laplace with strength k:

- ‚ñ† Pretend you saw every outcome k extra times

<!-- formula-not-decoded -->

- ‚ñ† k is the strength of the prior: how strongly your prior belief (before seeing the data) influences the resulting probability estimate.
- ‚ñ† k = 0: You are relying entirely on the observed data, no smoothing ‚Üí back to MLE
- ‚ñ† k = 1: basic Laplace
- ‚ñ† k &gt; 1: stronger smoothing - useful when you have less data or expect more unseen outcomes

## Generalized Laplace Smoothing

## ‚ñ† Laplace for conditionals:

- ‚ñ† Smooth each condition independently:

<!-- formula-not-decoded -->

<!-- image -->

<!-- image -->

<!-- image -->

Suppose we are trying to estimate the probability of drawing a red or blue bean given some condition y. For example, y is the day we drew the beans.

## We've observed:

- ¬∑ c(red, y) = 2
- ¬∑ c(blue, y) = 1
- ¬∑ c(y) = 3 (total draws with condition y)

What's P(green ‚à£ y)? 0! zero probability for unseen outcomes = bad for generalization!

Laplace Smoothing with k = 1 per condition:

‚Ä¢

c(red, y) = 2                                                 P(red | y) = (2+1)/(3+3)=3/6=0.5

‚Ä¢

c(blue, y) = 1                                               P(blue | y) = (1+1)/(3+3)=2/6 ÔÇª 0.33

‚Ä¢

c(green, y) = 0                                             P(green | y) = (0+1)/(3+3)=1/6=0.167

- ¬∑ c(y) = 3
- ¬∑ |X|=3

## Na√Øve Bayes: No Smoothing (Overfitting)

## ‚ñ† Relative probabilities (odds ratios):

## P(Wlham) P(Wlspam)

P(Wlspam)

P(Wlham)

inf

inf

inf

screens :

minute :

guaranteed :

inf

inf

inf

south-west :

nation :

morally :

inf

inf

$205.00 :

delivery :

inf

inf :

nicely :

extent

inf :

signature

...

inf :

seriously

...

What went wrong here?

<!-- image -->

## Na√Øve Bayes: With Smoothing

- ‚ñ† For real classification problems, smoothing is critical
- ‚ñ† New odds ratios:

## P(Wlham) P(Wlspam)

## P(Wlspam) P(Wlham)

28.8

verdana :

11.4

helvetica :

28.4

Credit :

10.8 :

seems

27.2

ORDER :

10.2

group :

26.9 :

&lt;FONT&gt;

8.4

ago :

26.5

money :

8.3 :

areas

...

...

Do these make more sense?

<!-- image -->

## Example: Na√Øve Bayes for Spam Filter

- ‚ñ† Step 1: Select a ML algorithm. We choose to model the problem with Na√Øve Bayes.
- ‚ñ† Step 2: Choose features to use.

<!-- image -->

| Y: The label (spam or ham)   | Y: The label (spam or ham)   |
|------------------------------|------------------------------|
| Y                            | P(Y)                         |
| ham                          | ?                            |
| spam                         | ?                            |

| F 1 : A feature (do I know the sender?)   | F 1 : A feature (do I know the sender?)   | F 1 : A feature (do I know the sender?)   |
|-------------------------------------------|-------------------------------------------|-------------------------------------------|
| F 1                                       | Y                                         | P(F 1 |Y)                                 |
| yes                                       | ham                                       | ?                                         |
| no                                        | ham                                       | ?                                         |
| yes                                       | spam                                      | ?                                         |
| no                                        | spam                                      | ?                                         |

| F 2 : Another feature (# of occurrences of FREE)   | F 2 : Another feature (# of occurrences of FREE)   | F 2 : Another feature (# of occurrences of FREE)   |
|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| F 2                                                | Y                                                  | P(F 2 |Y)                                          |
| 0                                                  | ham                                                | ?                                                  |
| 1                                                  | ham                                                | ?                                                  |
| 2                                                  | ham                                                | ?                                                  |
| 0                                                  | spam                                               | ?                                                  |
| 1                                                  | spam                                               | ?                                                  |
| 2                                                  | spam                                               | ?                                                  |

## Example: Na√Øve Bayes for Spam Filter

## ‚ñ† Step 3: Training: Use training data to fill in the probability tables.

| F 2 : # of occurrences of FREE   | F 2 : # of occurrences of FREE   | F 2 : # of occurrences of FREE   |
|----------------------------------|----------------------------------|----------------------------------|
| F 2                              | Y                                | P(F 2 |Y)                        |
| 0                                | ham                              | 0.5                              |
| 1                                | ham                              | 0.5                              |
| 2                                | ham                              | 0.0                              |
| 0                                | spam                             | 0.25                             |
| 1                                | spam                             | 0.50                             |
| 2                                | spam                             | 0.25                             |

| Training Data   | Training Data                        | Training Data   |
|-----------------|--------------------------------------|-----------------|
| #               | Email Text                           | Label           |
| 1               | Attached is myportfolio.             | ham             |
| 2               | Are you free for a meeting tomorrow? | ham             |
| 3               | Free unlimited credit cards!!!!      | spam            |
| 4               | Mail $10,000 check to this address   | spam            |
| 5               | Sign up now for 1 free Bitcoin       | spam            |
| 6               | Free money free money                | spam            |

- Row 4: P(F2=0 | Y=spam) = 0.25 because 1 out of 4 spam emails contains 'free' 0 times.
- Row 5: P(F2=1 | Y=spam) = 0.50 because 2 out of 4 spam emails contains 'free' 1 time.
- Row 6: P(F2=2 | Y=spam) = 0.25 because 1 out of 4 spam emails contains 'free' 2 times.

## Example: Na√Øve Bayes for Spam Filter

## ‚ñ† Model trained on a larger dataset:

<!-- image -->

| Y: The label (spam or ham)   | Y: The label (spam or ham)   |
|------------------------------|------------------------------|
| Y                            | P(Y)                         |
| ham                          | 0.6                          |
| spam                         | 0.4                          |

| F 1 : A feature (do I know the sender?)   | F 1 : A feature (do I know the sender?)   | F 1 : A feature (do I know the sender?)   |
|-------------------------------------------|-------------------------------------------|-------------------------------------------|
| F 1                                       | Y                                         | P(F 1 |Y)                                 |
| yes                                       | ham                                       | 0.7                                       |
| no                                        | ham                                       | 0.3                                       |
| yes                                       | spam                                      | 0.1                                       |
| no                                        | spam                                      | 0.9                                       |

| F 2 : Another feature (# of occurrences of FREE)   | F 2 : Another feature (# of occurrences of FREE)   | F 2 : Another feature (# of occurrences of FREE)   |
|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| F 2                                                | Y                                                  | P(F 2 |Y)                                          |
| 0                                                  | ham                                                | 0.85                                               |
| 1                                                  | ham                                                | 0.07                                               |
| 2                                                  | ham                                                | 0.08                                               |
| 0                                                  | spam                                               | 0.75                                               |
| 1                                                  | spam                                               | 0.12                                               |
| 2                                                  | spam                                               | 0.13                                               |

## Example: Na√Øve Bayes for Spam Filter

- ‚ñ† Step 4: Classification
- ‚ñ† Suppose you want to label this email from a known sender:
- ' Free food in Soda 430 today'
- ‚ñ† Step 4.1: Feature extraction:
- ‚ñ† F1 = yes, known sender
- ‚ñ† F2 = 1 occurrence of 'free'

<!-- image -->

## Example: Na√Øve Bayes for Spam Filter

- ‚ñ† Step 4.2: Inference
- ‚ñ† Instantiate features (evidence):
- ‚ñ† F1 = yes
- ‚ñ† F2 = 1
- ‚ñ† Compute joint probabilities:
- ‚ñ† P(Y = spam, F1 = yes, F2 = 1) = P(Y = spam) P(F1 = yes | spam) P(F2 = 1 | spam) = 0.4 * 0.1 * 0.12 = 0.0048
- ‚ñ† P(Y = ham, F1 = yes, F2 = 1) = P(Y = ham) P(F1 = yes | ham) P(F2 = 1 | ham) = 0.6 * 0.7 * 0.07 = 0.0294

| Y: The label (spam or ham)   | Y: The label (spam or ham)   |
|------------------------------|------------------------------|
| Y                            | P(Y)                         |
| ham                          | 0.6                          |
| spam                         | 0.4                          |

<!-- image -->

## ‚ñ† Normalize:

- ‚ñ† P(Y = spam | F1 = yes, F2 = 1) = 0.0048 / (0.0048+0.0294) = 0.14
- ‚ñ† P(Y = ham | F1 = yes, F2 = 1) = 0.0294 / (0.0048+0.0294) = 0.86

## ‚ñ† Classification result:

- ‚ñ† 14% chance the email is spam. 86% chance it's ham.
- ‚ñ† Or, if you don't need probabilities, note that 0.0294 &gt; 0.0048 and guess ham.

| F 1 : do I know the sender?   | F 1 : do I know the sender?   | F 1 : do I know the sender?   |
|-------------------------------|-------------------------------|-------------------------------|
| F 1                           | Y                             | P(F 1 |Y)                     |
| yes                           | ham                           | 0.7                           |
| no                            | ham                           | 0.3                           |
| yes                           | spam                          | 0.1                           |
| no                            | spam                          | 0.9                           |

| F 2 : # of occurrences of FREE   | F 2 : # of occurrences of FREE   | F 2 : # of occurrences of FREE   |
|----------------------------------|----------------------------------|----------------------------------|
| F 2                              | Y                                | P(F 2 |Y)                        |
| 0                                | ham                              | 0.85                             |
| 1                                | ham                              | 0.07                             |
| 2                                | ham                              | 0.08                             |
| 0                                | spam                             | 0.75                             |
| 1                                | spam                             | 0.12                             |
| 2                                | spam                             | 0.13                             |

## What we did today

## ‚ñ† Saw our first machine learning algorithm: Na√Øve Bayes

- ‚ñ† Model is a Bayes Net where features are independent given class label
- ‚ñ† Classification is just inference in Bayes Nets
- ‚ñ† Learning is just counting feature occurrences in training data
- ‚ñ† Saw Maximum Likelihood as a principled way to estimate parameters
- ‚ñ† Maximize probability of the data given model parameters
- ‚ñ† For Na√Øve Bayes, we solved maximization problem analytically
- ‚ñ† Saw that fitting training data too well can cause overfitting and we can smooth it